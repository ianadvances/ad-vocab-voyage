# VocabVoyage æ¶æ§‹èªªæ˜æ–‡ä»¶

æœ¬æ–‡ä»¶è©³ç´°èªªæ˜ VocabVoyage è‹±èªè©å½™å­¸ç¿’å¹³å°çš„æŠ€è¡“æ¶æ§‹ã€è¨­è¨ˆç†å¿µå’Œå¯¦ä½œç´°ç¯€ã€‚

## ç³»çµ±æ¦‚è¦½

VocabVoyage æ˜¯ä¸€å€‹åŸºæ–¼ç¾ä»£ AI æŠ€è¡“çš„è‹±èªå­¸ç¿’å¹³å°ï¼Œæ¡ç”¨å¾®æœå‹™æ¶æ§‹è¨­è¨ˆï¼Œæ•´åˆäº†å¤šç¨®å…ˆé€²æŠ€è¡“ä¾†æä¾›æ™ºèƒ½åŒ–çš„å­¸ç¿’é«”é©—ã€‚

### æ ¸å¿ƒè¨­è¨ˆç†å¿µ

- **AI å„ªå…ˆ**ï¼šä»¥äººå·¥æ™ºæ…§ç‚ºæ ¸å¿ƒï¼Œæä¾›æ™ºèƒ½åŒ–çš„å­¸ç¿’é«”é©—
- **ç”¨æˆ¶ä¸­å¿ƒ**ï¼šæ‰€æœ‰åŠŸèƒ½è¨­è¨ˆéƒ½ä»¥æå‡ç”¨æˆ¶å­¸ç¿’æ•ˆæœç‚ºç›®æ¨™
- **æ¨¡çµ„åŒ–æ¶æ§‹**ï¼šæ¡ç”¨é¬†è€¦åˆçš„æ¨¡çµ„åŒ–è¨­è¨ˆï¼Œä¾¿æ–¼ç¶­è­·å’Œæ“´å±•
- **é›²ç«¯åŸç”Ÿ**ï¼šè¨­è¨ˆç‚ºé›²ç«¯åŸç”Ÿæ‡‰ç”¨ï¼Œæ”¯æ´æ°´å¹³æ“´å±•å’Œé«˜å¯ç”¨æ€§
- **é–‹æºå‹å–„**ï¼šæ¡ç”¨é–‹æºæŠ€è¡“æ£§ï¼Œä¾¿æ–¼ç¤¾ç¾¤è²¢ç»å’Œè‡ªä¸»éƒ¨ç½²

## æ•´é«”æ¶æ§‹

### ç³»çµ±æ¶æ§‹åœ–

```mermaid
graph TB
    subgraph "å‰ç«¯å±¤ (Frontend Layer)"
        UI[Streamlit Web UI]
        UX[ç”¨æˆ¶é«”é©—ä»‹é¢]
    end
    
    subgraph "æ‡‰ç”¨å±¤ (Application Layer)"
        APP[ä¸»æ‡‰ç”¨ç¨‹å¼<br/>src/app.py]
        CONFIG[é…ç½®ç®¡ç†<br/>src/config.py]
    end
    
    subgraph "æ¥­å‹™é‚è¼¯å±¤ (Business Logic Layer)"
        AGENT[LangGraph ä»£ç†<br/>src/agents.py]
        DB[è³‡æ–™åº«æ“ä½œ<br/>src/database.py]
    end
    
    subgraph "AI æœå‹™å±¤ (AI Services Layer)"
        LLM[èªè¨€æ¨¡å‹æœå‹™]
        EMBED[åµŒå…¥æ¨¡å‹æœå‹™]
        RAG[RAG æª¢ç´¢ç³»çµ±]
    end
    
    subgraph "è³‡æ–™å±¤ (Data Layer)"
        FIREBASE[(Firebase<br/>Realtime Database<br/>ç”Ÿç”¢ç’°å¢ƒ)]
        CHROMA[(ChromaDB<br/>å‘é‡è³‡æ–™åº«<br/>è©å½™æª¢ç´¢)]
        SQLITE[(SQLite<br/>æœ¬åœ°è³‡æ–™åº«<br/>é–‹ç™¼ç’°å¢ƒ)]
    end
    
    subgraph "å¤–éƒ¨æœå‹™ (External Services)"
        OPENAI[OpenAI API]
        GEMINI[Google Gemini API]
        VERTEX[Vertex AI]
    end
    
    UI --> APP
    UX --> APP
    APP --> CONFIG
    APP --> AGENT
    APP --> DB
    
    AGENT --> LLM
    AGENT --> RAG
    DB --> FIREBASE
    
    LLM --> OPENAI
    LLM --> GEMINI
    EMBED --> OPENAI
    RAG --> CHROMA
    RAG --> EMBED
    
    DB --> SQLITE
    CONFIG --> VERTEX
```

### æŠ€è¡“æ£§æ¦‚è¦½

| å±¤ç´š | æŠ€è¡“ | ç”¨é€” | ç‰ˆæœ¬ |
|------|------|------|------|
| å‰ç«¯ | Streamlit | Web UI æ¡†æ¶ | 1.28+ |
| å¾Œç«¯ | Python | æ ¸å¿ƒé–‹ç™¼èªè¨€ | 3.11+ |
| AI æ¡†æ¶ | LangChain | LLM æ‡‰ç”¨é–‹ç™¼ | 0.1+ |
| AI æ¡†æ¶ | LangGraph | æ™ºèƒ½ä»£ç†å·¥ä½œæµç¨‹ | 0.0.40+ |
| è³‡æ–™åº« | Firebase | é›²ç«¯å³æ™‚è³‡æ–™åº« | - |
| å‘é‡è³‡æ–™åº« | ChromaDB | å‘é‡å„²å­˜å’Œæª¢ç´¢ | 0.4+ |
| æœ¬åœ°è³‡æ–™åº« | SQLite | æœ¬åœ°è³‡æ–™å„²å­˜ | 3.0+ |
| å®¹å™¨åŒ– | Docker | æ‡‰ç”¨ç¨‹å¼å®¹å™¨åŒ– | 20.0+ |
| å¥—ä»¶ç®¡ç† | Poetry | Python ä¾è³´ç®¡ç† | 1.7+ |

## æ ¸å¿ƒæ¨¡çµ„æ¶æ§‹

### 1. ä¸»æ‡‰ç”¨ç¨‹å¼æ¨¡çµ„ (src/app.py)

ä¸»æ‡‰ç”¨ç¨‹å¼æ¨¡çµ„æ˜¯æ•´å€‹ç³»çµ±çš„å…¥å£é»ï¼Œè² è²¬å”èª¿å„å€‹å­ç³»çµ±çš„é‹ä½œã€‚

```python
# ä¸»è¦è·è²¬
class VocabVoyageApp:
    """VocabVoyage ä¸»æ‡‰ç”¨ç¨‹å¼é¡åˆ¥"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ‡‰ç”¨ç¨‹å¼çµ„ä»¶"""
        self.config = load_config()
        self.database = VocabDatabase()
        self.agent_system = create_vocab_chain()
        
    def run(self):
        """å•Ÿå‹• Streamlit æ‡‰ç”¨ç¨‹å¼"""
        # è¨­å®šé é¢é…ç½®
        # åˆå§‹åŒ–æœƒè©±ç‹€æ…‹
        # æ¸²æŸ“ç”¨æˆ¶ä»‹é¢
        # è™•ç†ç”¨æˆ¶äº’å‹•
```

**æ ¸å¿ƒåŠŸèƒ½ï¼š**
- ğŸ¨ **UI æ¸²æŸ“**ï¼šç®¡ç† Streamlit ä»‹é¢çš„æ¸²æŸ“å’Œæ›´æ–°
- ğŸ”„ **ç‹€æ…‹ç®¡ç†**ï¼šç¶­è­·ç”¨æˆ¶æœƒè©±ç‹€æ…‹å’Œå°è©±æ­·å²
- ğŸ¯ **äº‹ä»¶è™•ç†**ï¼šè™•ç†ç”¨æˆ¶è¼¸å…¥å’Œç³»çµ±å›æ‡‰
- ğŸ”— **æ¨¡çµ„æ•´åˆ**ï¼šå”èª¿å„å€‹å­ç³»çµ±çš„å”ä½œ

### 2. æ™ºèƒ½ä»£ç†æ¨¡çµ„ (src/agents.py)

æ™ºèƒ½ä»£ç†æ¨¡çµ„æ˜¯ç³»çµ±çš„æ ¸å¿ƒ AI çµ„ä»¶ï¼ŒåŸºæ–¼ LangGraph æ¡†æ¶å¯¦ç¾è¤‡é›œçš„æ±ºç­–é‚è¼¯ã€‚

#### LangGraph å·¥ä½œæµç¨‹æ¶æ§‹

```mermaid
graph TD
    START([é–‹å§‹]) --> AGENT[æ™ºèƒ½ä»£ç†ç¯€é»]
    
    AGENT --> DECISION{æ±ºç­–åˆ¤æ–·}
    
    DECISION -->|éœ€è¦å·¥å…·| TOOLS[å·¥å…·åŸ·è¡Œç¯€é»]
    DECISION -->|ç›´æ¥å›æ‡‰| GENERATE[å›æ‡‰ç”Ÿæˆç¯€é»]
    
    TOOLS --> TOOL_VOCAB[è©å½™æŸ¥è©¢å·¥å…·]
    TOOLS --> TOOL_CATEGORY[ä¸»é¡Œå­¸ç¿’å·¥å…·]
    TOOLS --> TOOL_QUIZ[æ¸¬é©—ç”Ÿæˆå·¥å…·]
    
    TOOL_VOCAB --> GENERATE
    TOOL_CATEGORY --> GENERATE
    TOOL_QUIZ --> GENERATE
    
    GENERATE --> END([çµæŸ])
    
    subgraph "ç‹€æ…‹ç®¡ç†"
        STATE[VocabState]
        MESSAGES[å°è©±è¨Šæ¯]
        CONTEXT[ä¸Šä¸‹æ–‡è³‡è¨Š]
        USER_ID[ç”¨æˆ¶è­˜åˆ¥]
    end
```

#### ç‹€æ…‹å®šç¾©

```python
class VocabState(TypedDict):
    """å®šç¾© LangGraph å·¥ä½œæµç¨‹çš„ç‹€æ…‹çµæ§‹"""
    messages: Annotated[Sequence[BaseMessage], add_messages]
    context: dict  # ä¸Šä¸‹æ–‡è³‡è¨Š
    user_id: str   # ç”¨æˆ¶è­˜åˆ¥ç¢¼
```

#### æ ¸å¿ƒç¯€é»å¯¦ä½œ

**1. æ™ºèƒ½ä»£ç†ç¯€é» (Agent Node)**
```python
def agent(state: VocabState):
    """
    æ™ºèƒ½ä»£ç†ç¯€é»ï¼šåˆ†æç”¨æˆ¶æ„åœ–ä¸¦æ±ºå®šè™•ç†ç­–ç•¥
    
    è·è²¬ï¼š
    - ç†è§£ç”¨æˆ¶è¼¸å…¥çš„èªç¾©å’Œæ„åœ–
    - æ±ºå®šæ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·
    - é¸æ“‡æœ€é©åˆçš„å·¥å…·æˆ–ç›´æ¥ç”Ÿæˆå›æ‡‰
    """
    messages = state["messages"]
    
    # ç³»çµ±æç¤ºè©å®šç¾©ä»£ç†è¡Œç‚º
    system_message = """ä½ æ˜¯ä¸€å€‹è‹±èªå­¸ç¿’åŠ©æ‰‹çš„è·¯ç”±å™¨ã€‚
    ä½ çš„ä»»å‹™æ˜¯åˆ†æç”¨æˆ¶å•é¡Œä¸¦æ±ºå®šæœ€ä½³çš„è™•ç†æ–¹å¼ï¼š
    - å–®å­—æŸ¥è©¢ â†’ ä½¿ç”¨ search_vocabulary_details å·¥å…·
    - ä¸»é¡Œå­¸ç¿’ â†’ ä½¿ç”¨ category_vocabulary_list å·¥å…·  
    - æ¸¬é©—ç”Ÿæˆ â†’ ä½¿ç”¨ vocabulary_quiz_generator å·¥å…·
    - ä¸€èˆ¬å°è©± â†’ ç›´æ¥ç”Ÿæˆå›æ‡‰
    """
    
    # ä½¿ç”¨ GPT æ¨¡å‹é€²è¡Œæ±ºç­–
    model = ChatOpenAI(temperature=0.7, model="gpt-4o-mini")
    model = model.bind_tools(tools)
    response = model.invoke([HumanMessage(content=system_message)] + messages)
    
    return {
        "messages": [response],
        "context": state["context"],
        "user_id": state["user_id"]
    }
```

**2. å·¥å…·åŸ·è¡Œç¯€é» (Tool Node)**
```python
# ä½¿ç”¨ LangGraph å…§å»ºçš„ ToolNode
tool_node = ToolNode(tools=tools)

# å·¥å…·æœƒæ ¹æ“šä»£ç†çš„æ±ºç­–è‡ªå‹•åŸ·è¡Œç›¸æ‡‰çš„åŠŸèƒ½
```

**3. å›æ‡‰ç”Ÿæˆç¯€é» (Generate Node)**
```python
def generate_response(state: VocabState):
    """
    å›æ‡‰ç”Ÿæˆç¯€é»ï¼šç”Ÿæˆæœ€çµ‚çš„ç”¨æˆ¶å›æ‡‰
    
    è·è²¬ï¼š
    - æ•´åˆå·¥å…·åŸ·è¡Œçµæœ
    - ç”Ÿæˆè‡ªç„¶æµæš¢çš„å›æ‡‰
    - ç¶­è­·å°è©±çš„é€£è²«æ€§
    """
    messages = state["messages"]
    
    # æª¢æŸ¥æ˜¯å¦æœ‰å·¥å…·åŸ·è¡Œçµæœ
    last_message = messages[-1]
    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
        # å·¥å…·å·²åŸ·è¡Œï¼Œç›´æ¥è¿”å›çµæœ
        return {"messages": messages}
    
    # ç”Ÿæˆç›´æ¥å›æ‡‰
    model = ChatOpenAI(temperature=0.7, model="gpt-4o-mini")
    response = model.invoke(messages)
    
    return {"messages": [response]}
```

#### æ¢ä»¶é‚Šé‚è¼¯

```python
def tools_condition(state: VocabState):
    """
    æ±ºå®šå·¥ä½œæµç¨‹çš„ä¸‹ä¸€æ­¥ï¼šåŸ·è¡Œå·¥å…·æˆ–ç›´æ¥ç”Ÿæˆå›æ‡‰
    """
    messages = state["messages"]
    last_message = messages[-1]
    
    # æª¢æŸ¥ä»£ç†æ˜¯å¦æ±ºå®šä½¿ç”¨å·¥å…·
    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
        return "tools"
    else:
        return END
```

### 3. å·¥å…·ç³»çµ±æ¶æ§‹

#### å·¥å…·å®šç¾©å’Œè¨»å†Š

```python
from langchain.tools import Tool

tools = [
    Tool(
        name="search_vocabulary_details",
        description="""ç”¨æ–¼æŸ¥è©¢å–®å€‹è‹±æ–‡å–®å­—æˆ–ç‰‡èªçš„è©³ç´°è³‡è¨Š""",
        func=search_vocabulary,
        return_direct=True
    ),
    Tool(
        name="category_vocabulary_list", 
        description="""ç”¨æ–¼ç²å–ç‰¹å®šä¸»é¡Œçš„ç›¸é—œè‹±æ–‡å–®å­—åˆ—è¡¨""",
        func=get_category_vocabulary,
        return_direct=True
    ),
    Tool(
        name="vocabulary_quiz_generator",
        description="""ç”¨æ–¼ç”Ÿæˆç‰¹å®šä¸»é¡Œçš„è‹±æ–‡å–®å­—æ¸¬é©—""",
        func=generate_quiz,
        return_direct=True
    )
]
```

#### å·¥å…·å¯¦ä½œç´°ç¯€

**1. è©å½™æŸ¥è©¢å·¥å…·**
```python
def search_vocabulary(query: str) -> str:
    """
    è©å½™æŸ¥è©¢å·¥å…·å¯¦ä½œ
    
    æµç¨‹ï¼š
    1. æ¥æ”¶ç”¨æˆ¶æŸ¥è©¢çš„å–®å­—
    2. ä½¿ç”¨ LLM ç”Ÿæˆçµæ§‹åŒ–çš„è©å½™è³‡è¨Š
    3. è¿”å›æ ¼å¼åŒ–çš„çµæœ
    """
    # ä½¿ç”¨å°ˆé–€çš„æç¤ºè©æ¨¡æ¿
    prompt_template = PromptTemplate(
        template=SYSTEM_PROMPTS["search"] + "\n\næŸ¥è©¢å–®å­—: {query}",
        input_variables=["query"]
    )
    
    # å»ºç«‹è™•ç†éˆ
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)
    chain = prompt_template | llm | StrOutputParser()
    
    # åŸ·è¡ŒæŸ¥è©¢ä¸¦è¿”å›çµæœ
    response = chain.invoke({"query": query})
    return response
```

**2. RAG æª¢ç´¢å·¥å…·**
```python
def get_category_vocabulary(category: str) -> str:
    """
    åŸºæ–¼ RAG çš„ä¸»é¡Œè©å½™æª¢ç´¢å·¥å…·
    
    æµç¨‹ï¼š
    1. è¨­å®šå‘é‡è³‡æ–™åº«æª¢ç´¢å™¨
    2. æ ¹æ“šä¸»é¡Œæª¢ç´¢ç›¸é—œæ–‡ä»¶
    3. ä½¿ç”¨ LLM è™•ç†æª¢ç´¢çµæœ
    4. ç”Ÿæˆçµæ§‹åŒ–çš„è©å½™åˆ—è¡¨
    """
    # è¨­å®š RAG æª¢ç´¢å™¨
    retriever = setup_rag()
    
    # æª¢ç´¢ç›¸é—œæ–‡ä»¶
    docs = retriever.invoke(category)
    context = "\n".join(doc.page_content for doc in docs)
    
    # ä½¿ç”¨ LLM è™•ç†æª¢ç´¢çµæœ
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)
    prompt = PromptTemplate(
        template=SYSTEM_PROMPTS["category"],
        input_variables=["context"]
    )
    chain = prompt | llm | StrOutputParser()
    
    response = chain.invoke({"context": context})
    return response
```

### 4. RAG ç³»çµ±æ¶æ§‹

#### RAG ç³»çµ±çµ„ä»¶

```mermaid
graph LR
    subgraph "RAG æª¢ç´¢ç³»çµ±"
        QUERY[ç”¨æˆ¶æŸ¥è©¢] --> EMBED[æŸ¥è©¢å‘é‡åŒ–]
        EMBED --> SEARCH[ç›¸ä¼¼åº¦æœå°‹]
        SEARCH --> RETRIEVE[æ–‡ä»¶æª¢ç´¢]
        RETRIEVE --> CONTEXT[ä¸Šä¸‹æ–‡æ•´åˆ]
        CONTEXT --> LLM[LLM ç”Ÿæˆ]
        LLM --> RESPONSE[çµæ§‹åŒ–å›æ‡‰]
    end
    
    subgraph "å‘é‡è³‡æ–™åº«"
        CHROMA_DB[(ChromaDB)]
        VECTORS[è©å½™å‘é‡]
        METADATA[å…ƒè³‡æ–™]
    end
    
    subgraph "åµŒå…¥æœå‹™"
        OPENAI_EMBED[OpenAI Embeddings]
        MODEL[text-embedding-3-small]
    end
    
    EMBED --> OPENAI_EMBED
    SEARCH --> CHROMA_DB
    CHROMA_DB --> VECTORS
    CHROMA_DB --> METADATA
```

#### RAG å¯¦ä½œç´°ç¯€

```python
def setup_rag():
    """
    è¨­å®š RAG æª¢ç´¢ç³»çµ±
    
    çµ„ä»¶ï¼š
    - ChromaDB å‘é‡è³‡æ–™åº«
    - OpenAI åµŒå…¥æ¨¡å‹
    - ç›¸ä¼¼åº¦æª¢ç´¢å™¨
    """
    # åˆå§‹åŒ–å‘é‡è³‡æ–™åº«
    vectorstore = Chroma(
        persist_directory="./data/chroma_db",
        embedding_function=OpenAIEmbeddings(
            model="text-embedding-3-small"
        ),
        collection_name="vocabulary_v1"
    )
    
    # è¨­å®šæª¢ç´¢å™¨
    retriever = vectorstore.as_retriever(
        search_type="similarity",
        search_kwargs={"k": 1}  # æª¢ç´¢æœ€ç›¸é—œçš„ 1 å€‹æ–‡ä»¶
    )
    
    return retriever
```

#### å‘é‡è³‡æ–™åº«çµæ§‹

```python
# æ–‡ä»¶çµæ§‹ç¯„ä¾‹
{
    "page_content": "å•†æ¥­è©å½™å…§å®¹...",
    "metadata": {
        "category": "business",
        "source": "business_vocabulary.txt",
        "word_count": 150,
        "difficulty": "intermediate"
    }
}
```

### è³‡æ–™åº«æ¶æ§‹è¨­è¨ˆ

VocabVoyage æ¡ç”¨å¤šè³‡æ–™åº«æ¶æ§‹ï¼Œæ ¹æ“šéƒ¨ç½²ç’°å¢ƒå’Œç”¨é€”è‡ªå‹•é¸æ“‡åˆé©çš„è³‡æ–™åº«ï¼š

| ç’°å¢ƒé¡å‹ | è³‡æ–™åº«é¡å‹ | æª”æ¡ˆä½ç½® | ç”¨é€” | ç‰¹é» |
|---------|-----------|----------|------|------|
| æœ¬åœ°é–‹ç™¼ | SQLite | `data/vocab_learning.db` | é–‹ç™¼å’Œæ¸¬è©¦ | è¼•é‡ç´šã€ç„¡éœ€é…ç½®ã€é©åˆå€‹äººä½¿ç”¨ |
| ç”Ÿç”¢ç’°å¢ƒ | Firebase Realtime DB | é›²ç«¯ | æ­£å¼éƒ¨ç½² | å³æ™‚åŒæ­¥ã€å¤šç”¨æˆ¶æ”¯æ´ã€é›²ç«¯å‚™ä»½ |
| é€šç”¨ | ChromaDB | `data/chroma_db/` | å‘é‡æª¢ç´¢ | èªç¾©æœå°‹ã€RAG æ”¯æ´ |

#### ç’°å¢ƒåˆ‡æ›é‚è¼¯

ç³»çµ±æ ¹æ“š `ENV` ç’°å¢ƒè®Šæ•¸è‡ªå‹•é¸æ“‡è³‡æ–™åº«é¡å‹ï¼š

```python
# åœ¨ src/app.py ä¸­çš„è‡ªå‹•åˆ‡æ›é‚è¼¯
if config.is_development():  # ENV=local/dev/development/loc
    from notebooks.models_sqlite import VocabDatabase  # SQLite ç‰ˆæœ¬
else:  # ENV=prod/production
    from src.database import VocabDatabase  # Firebase ç‰ˆæœ¬
```

**SQLite æ¨¡å¼ç‰¹é»**ï¼š
- âœ… ç„¡éœ€ç¶²è·¯é€£ç·šå³å¯é‹è¡Œ
- âœ… é›¶é…ç½®ï¼Œè‡ªå‹•åˆå§‹åŒ–
- âœ… é©åˆé–‹ç™¼å’Œå€‹äººä½¿ç”¨
- âœ… è³‡æ–™å„²å­˜åœ¨æœ¬åœ°æª”æ¡ˆä¸­
- âš ï¸ ä¸æ”¯æ´å¤šç”¨æˆ¶åŒæ™‚å­˜å–

**Firebase æ¨¡å¼ç‰¹é»**ï¼š
- âœ… æ”¯æ´å¤šç”¨æˆ¶å³æ™‚åŒæ­¥
- âœ… é›²ç«¯å‚™ä»½å’Œæ¢å¾©
- âœ… é«˜å¯ç”¨æ€§å’Œæ“´å±•æ€§
- âš ï¸ éœ€è¦ç¶²è·¯é€£ç·šå’Œ API é…ç½®
- âš ï¸ å¯èƒ½ç”¢ç”Ÿä½¿ç”¨è²»ç”¨

### 5. è³‡æ–™åº«æ¶æ§‹

#### Firebase Realtime Database çµæ§‹

```json
{
  "users": {
    "user_id_1": {
      "username": "john_doe",
      "created_at": "2024-01-15T10:30:00Z",
      "preferences": {
        "language": "zh-TW",
        "difficulty": "intermediate"
      }
    }
  },
  "vocabulary": {
    "user_id_1": {
      "vocab_id_1": {
        "word": "innovation",
        "definition": "å‰µæ–°ï¼›é©æ–°",
        "examples": [
          "The company's innovation...",
          "Her innovation in teaching..."
        ],
        "notes": "å¸¸ç”¨æ–¼å•†æ¥­èªå¢ƒ",
        "created_at": "2024-01-15T11:00:00Z"
      }
    }
  },
  "chat_sessions": {
    "user_id_1": {
      "session_id_1": {
        "name": "å•†æ¥­è‹±æ–‡å­¸ç¿’",
        "created_at": "2024-01-15T09:00:00Z",
        "messages": {
          "message_id_1": {
            "role": "user",
            "content": "æŸ¥è©¢å–®å­— innovation",
            "timestamp": "2024-01-15T09:05:00Z"
          },
          "message_id_2": {
            "role": "assistant", 
            "content": "å–®å­—ï¼šinnovation...",
            "timestamp": "2024-01-15T09:05:30Z"
          }
        }
      }
    }
  }
}
```

#### è³‡æ–™åº«æ“ä½œæ¨¡çµ„

```python
class VocabDatabase:
    """Firebase è³‡æ–™åº«æ“ä½œé¡åˆ¥"""
    
    def __init__(self):
        """åˆå§‹åŒ– Firebase é€£æ¥"""
        self.db = self._initialize_firebase()
    
    def _initialize_firebase(self):
        """åˆå§‹åŒ– Firebase æœå‹™"""
        # è¼‰å…¥æœå‹™å¸³æˆ¶é‡‘é‘°
        # åˆå§‹åŒ– Firebase Admin SDK
        # è¿”å›è³‡æ–™åº«åƒè€ƒ
    
    def get_or_create_user(self, username: str) -> str:
        """ç²å–æˆ–å‰µå»ºç”¨æˆ¶å¸³æˆ¶"""
        # æª¢æŸ¥ç”¨æˆ¶æ˜¯å¦å­˜åœ¨
        # å¦‚ä¸å­˜åœ¨å‰‡å‰µå»ºæ–°ç”¨æˆ¶
        # è¿”å›ç”¨æˆ¶ ID
    
    def add_vocabulary(self, user_id: str, word: str, 
                      definition: str, examples: List[str], 
                      notes: str = "") -> bool:
        """æ·»åŠ å–®å­—åˆ°ç”¨æˆ¶è©å½™æœ¬"""
        # æª¢æŸ¥å–®å­—æ˜¯å¦å·²å­˜åœ¨
        # å‰µå»ºæ–°çš„è©å½™è¨˜éŒ„
        # å„²å­˜åˆ° Firebase
    
    def get_user_vocabulary(self, user_id: str) -> List[dict]:
        """ç²å–ç”¨æˆ¶çš„è©å½™åˆ—è¡¨"""
        # å¾ Firebase æª¢ç´¢ç”¨æˆ¶è©å½™
        # æ ¼å¼åŒ–ä¸¦è¿”å›çµæœ
```

### 6. é…ç½®ç®¡ç†æ¶æ§‹

#### é…ç½®æ¨¡çµ„è¨­è¨ˆ

```python
# src/config.py
class Config:
    """æ‡‰ç”¨ç¨‹å¼é…ç½®ç®¡ç†é¡åˆ¥"""
    
    def __init__(self):
        """è¼‰å…¥é…ç½®è¨­å®š"""
        self.openai_api_key = self._get_env_var("OPENAI_API_KEY")
        self.firebase_config = self._load_firebase_config()
        self.streamlit_config = self._load_streamlit_config()
    
    def _get_env_var(self, key: str, default: str = None) -> str:
        """å®‰å…¨åœ°ç²å–ç’°å¢ƒè®Šæ•¸"""
        value = os.getenv(key, default)
        if not value:
            raise ConfigurationError(f"å¿…è¦çš„ç’°å¢ƒè®Šæ•¸ {key} æœªè¨­å®š")
        return value
    
    def _load_firebase_config(self) -> dict:
        """è¼‰å…¥ Firebase é…ç½®"""
        # è¼‰å…¥æœå‹™å¸³æˆ¶é‡‘é‘°æª”æ¡ˆ
        # é©—è­‰é…ç½®å®Œæ•´æ€§
        # è¿”å›é…ç½®å­—å…¸
    
    def validate_config(self) -> bool:
        """é©—è­‰é…ç½®å®Œæ•´æ€§"""
        # æª¢æŸ¥æ‰€æœ‰å¿…è¦çš„é…ç½®é …ç›®
        # æ¸¬è©¦å¤–éƒ¨æœå‹™é€£æ¥
        # è¿”å›é©—è­‰çµæœ
```

#### ç’°å¢ƒè®Šæ•¸ç®¡ç†

```bash
# .env æª”æ¡ˆçµæ§‹
# OpenAI è¨­å®š
OPENAI_API_KEY=sk-your-api-key-here
OPENAI_MODEL=gpt-4o-mini
OPENAI_TEMPERATURE=0.7

# Firebase è¨­å®š
GOOGLE_APPLICATION_CREDENTIALS=./FirebaseKey.json
FIREBASE_DATABASE_URL=https://your-project.firebaseio.com/

# Streamlit è¨­å®š
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=0.0.0.0
STREAMLIT_THEME_PRIMARY_COLOR=#FF6B6B

# ChromaDB è¨­å®š
CHROMA_DB_PATH=./data/chroma_db
CHROMA_COLLECTION_NAME=vocabulary_v1

# æ—¥èªŒè¨­å®š
LOG_LEVEL=INFO
LOG_FILE=vocabvoyage.log
```

## è³‡æ–™æµç¨‹æ¶æ§‹

### 1. ç”¨æˆ¶äº’å‹•æµç¨‹

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ¶
    participant UI as Streamlit UI
    participant APP as ä¸»æ‡‰ç”¨ç¨‹å¼
    participant AGENT as LangGraph ä»£ç†
    participant TOOLS as å·¥å…·ç³»çµ±
    participant DB as è³‡æ–™åº«
    participant LLM as èªè¨€æ¨¡å‹
    
    U->>UI: è¼¸å…¥æŸ¥è©¢
    UI->>APP: è™•ç†ç”¨æˆ¶è¼¸å…¥
    APP->>AGENT: å•Ÿå‹•ä»£ç†å·¥ä½œæµç¨‹
    
    AGENT->>LLM: åˆ†æç”¨æˆ¶æ„åœ–
    LLM->>AGENT: è¿”å›æ±ºç­–çµæœ
    
    alt éœ€è¦ä½¿ç”¨å·¥å…·
        AGENT->>TOOLS: åŸ·è¡Œç›¸æ‡‰å·¥å…·
        TOOLS->>LLM: èª¿ç”¨èªè¨€æ¨¡å‹
        LLM->>TOOLS: è¿”å›è™•ç†çµæœ
        TOOLS->>AGENT: è¿”å›å·¥å…·çµæœ
    else ç›´æ¥å›æ‡‰
        AGENT->>LLM: ç”Ÿæˆç›´æ¥å›æ‡‰
        LLM->>AGENT: è¿”å›å›æ‡‰å…§å®¹
    end
    
    AGENT->>APP: è¿”å›æœ€çµ‚çµæœ
    APP->>DB: å„²å­˜å°è©±è¨˜éŒ„
    APP->>UI: æ›´æ–°ç”¨æˆ¶ä»‹é¢
    UI->>U: é¡¯ç¤ºå›æ‡‰çµæœ
```

### 2. RAG æª¢ç´¢æµç¨‹

```mermaid
sequenceDiagram
    participant TOOL as ä¸»é¡Œå­¸ç¿’å·¥å…·
    participant RAG as RAG ç³»çµ±
    participant EMBED as åµŒå…¥æœå‹™
    participant CHROMA as ChromaDB
    participant LLM as èªè¨€æ¨¡å‹
    
    TOOL->>RAG: ä¸»é¡ŒæŸ¥è©¢è«‹æ±‚
    RAG->>EMBED: æŸ¥è©¢å‘é‡åŒ–
    EMBED->>RAG: è¿”å›æŸ¥è©¢å‘é‡
    
    RAG->>CHROMA: ç›¸ä¼¼åº¦æœå°‹
    CHROMA->>RAG: è¿”å›ç›¸é—œæ–‡ä»¶
    
    RAG->>LLM: æ•´åˆä¸Šä¸‹æ–‡ç”Ÿæˆ
    LLM->>RAG: è¿”å›çµæ§‹åŒ–çµæœ
    RAG->>TOOL: è¿”å›æœ€çµ‚çµæœ
```

### 3. è³‡æ–™å„²å­˜æµç¨‹

```mermaid
sequenceDiagram
    participant APP as ä¸»æ‡‰ç”¨ç¨‹å¼
    participant DB as è³‡æ–™åº«æ¨¡çµ„
    participant FIREBASE as Firebase
    participant LOCAL as æœ¬åœ°å„²å­˜
    
    APP->>DB: å„²å­˜è«‹æ±‚
    
    alt ç”¨æˆ¶è³‡æ–™
        DB->>FIREBASE: å„²å­˜åˆ°é›²ç«¯è³‡æ–™åº«
        FIREBASE->>DB: ç¢ºèªå„²å­˜æˆåŠŸ
    else å°è©±è¨˜éŒ„
        DB->>FIREBASE: å„²å­˜èŠå¤©è¨˜éŒ„
        FIREBASE->>DB: ç¢ºèªå„²å­˜æˆåŠŸ
    else å¿«å–è³‡æ–™
        DB->>LOCAL: å„²å­˜åˆ°æœ¬åœ°å¿«å–
        LOCAL->>DB: ç¢ºèªå„²å­˜æˆåŠŸ
    end
    
    DB->>APP: è¿”å›å„²å­˜çµæœ
```

## å®‰å…¨æ¶æ§‹

### 1. API é‡‘é‘°ç®¡ç†

```python
class SecureConfig:
    """å®‰å…¨é…ç½®ç®¡ç†"""
    
    def __init__(self):
        """åˆå§‹åŒ–å®‰å…¨é…ç½®"""
        self._api_keys = {}
        self._load_encrypted_keys()
    
    def _load_encrypted_keys(self):
        """è¼‰å…¥åŠ å¯†çš„ API é‡‘é‘°"""
        # å¾ç’°å¢ƒè®Šæ•¸è¼‰å…¥é‡‘é‘°
        # é©—è­‰é‡‘é‘°æ ¼å¼å’Œæœ‰æ•ˆæ€§
        # å¯¦ä½œé‡‘é‘°è¼ªæ›æ©Ÿåˆ¶
    
    def get_api_key(self, service: str) -> str:
        """å®‰å…¨åœ°ç²å– API é‡‘é‘°"""
        # æª¢æŸ¥é‡‘é‘°æ˜¯å¦å­˜åœ¨
        # è¨˜éŒ„é‡‘é‘°ä½¿ç”¨æƒ…æ³
        # è¿”å›è§£å¯†å¾Œçš„é‡‘é‘°
```

### 2. è³‡æ–™åŠ å¯†

```python
class DataEncryption:
    """è³‡æ–™åŠ å¯†æœå‹™"""
    
    def encrypt_user_data(self, data: dict) -> dict:
        """åŠ å¯†ç”¨æˆ¶æ•æ„Ÿè³‡æ–™"""
        # è­˜åˆ¥æ•æ„Ÿæ¬„ä½
        # ä½¿ç”¨ AES åŠ å¯†
        # è¿”å›åŠ å¯†å¾Œçš„è³‡æ–™
    
    def decrypt_user_data(self, encrypted_data: dict) -> dict:
        """è§£å¯†ç”¨æˆ¶è³‡æ–™"""
        # é©—è­‰è³‡æ–™å®Œæ•´æ€§
        # è§£å¯†æ•æ„Ÿæ¬„ä½
        # è¿”å›åŸå§‹è³‡æ–™
```

### 3. å­˜å–æ§åˆ¶

```python
class AccessControl:
    """å­˜å–æ§åˆ¶ç®¡ç†"""
    
    def authenticate_user(self, user_id: str) -> bool:
        """ç”¨æˆ¶èº«ä»½é©—è­‰"""
        # é©—è­‰ç”¨æˆ¶èº«ä»½
        # æª¢æŸ¥å¸³æˆ¶ç‹€æ…‹
        # è¨˜éŒ„ç™»å…¥äº‹ä»¶
    
    def authorize_action(self, user_id: str, action: str) -> bool:
        """æ“ä½œæˆæ¬Šæª¢æŸ¥"""
        # æª¢æŸ¥ç”¨æˆ¶æ¬Šé™
        # é©—è­‰æ“ä½œåˆæ³•æ€§
        # è¨˜éŒ„æˆæ¬Šäº‹ä»¶
```

## æ•ˆèƒ½å„ªåŒ–æ¶æ§‹

### 1. å¿«å–ç­–ç•¥

```python
class CacheManager:
    """å¿«å–ç®¡ç†ç³»çµ±"""
    
    def __init__(self):
        """åˆå§‹åŒ–å¿«å–ç³»çµ±"""
        self.memory_cache = {}
        self.redis_cache = None  # å¯é¸çš„ Redis å¿«å–
    
    def get_cached_response(self, query_hash: str) -> Optional[str]:
        """ç²å–å¿«å–çš„å›æ‡‰"""
        # æª¢æŸ¥è¨˜æ†¶é«”å¿«å–
        # æª¢æŸ¥æŒä¹…åŒ–å¿«å–
        # è¿”å›å¿«å–çµæœæˆ– None
    
    def cache_response(self, query_hash: str, response: str, ttl: int = 3600):
        """å¿«å–å›æ‡‰çµæœ"""
        # å„²å­˜åˆ°è¨˜æ†¶é«”å¿«å–
        # å„²å­˜åˆ°æŒä¹…åŒ–å¿«å–
        # è¨­å®šéæœŸæ™‚é–“
```

### 2. é€£æ¥æ± ç®¡ç†

```python
class ConnectionPool:
    """è³‡æ–™åº«é€£æ¥æ± ç®¡ç†"""
    
    def __init__(self, max_connections: int = 10):
        """åˆå§‹åŒ–é€£æ¥æ± """
        self.max_connections = max_connections
        self.active_connections = []
        self.idle_connections = []
    
    def get_connection(self):
        """ç²å–è³‡æ–™åº«é€£æ¥"""
        # æª¢æŸ¥ç©ºé–’é€£æ¥
        # å‰µå»ºæ–°é€£æ¥ï¼ˆå¦‚éœ€è¦ï¼‰
        # è¿”å›å¯ç”¨é€£æ¥
    
    def release_connection(self, connection):
        """é‡‹æ”¾è³‡æ–™åº«é€£æ¥"""
        # æ¸…ç†é€£æ¥ç‹€æ…‹
        # è¿”å›åˆ°ç©ºé–’æ± 
        # ç®¡ç†é€£æ¥ç”Ÿå‘½é€±æœŸ
```

### 3. éåŒæ­¥è™•ç†

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

class AsyncProcessor:
    """éåŒæ­¥è™•ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–éåŒæ­¥è™•ç†å™¨"""
        self.executor = ThreadPoolExecutor(max_workers=4)
    
    async def process_multiple_queries(self, queries: List[str]) -> List[str]:
        """ä¸¦è¡Œè™•ç†å¤šå€‹æŸ¥è©¢"""
        # å‰µå»ºéåŒæ­¥ä»»å‹™
        # ä¸¦è¡ŒåŸ·è¡ŒæŸ¥è©¢
        # æ”¶é›†ä¸¦è¿”å›çµæœ
        
        tasks = [
            asyncio.create_task(self.process_single_query(query))
            for query in queries
        ]
        
        results = await asyncio.gather(*tasks)
        return results
```

## ç›£æ§å’Œæ—¥èªŒæ¶æ§‹

### 1. æ—¥èªŒç³»çµ±

```python
import logging
from datetime import datetime

class VocabLogger:
    """VocabVoyage æ—¥èªŒç³»çµ±"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ—¥èªŒç³»çµ±"""
        self.logger = self._setup_logger()
    
    def _setup_logger(self):
        """è¨­å®šæ—¥èªŒé…ç½®"""
        logger = logging.getLogger('vocabvoyage')
        logger.setLevel(logging.INFO)
        
        # æª”æ¡ˆè™•ç†å™¨
        file_handler = logging.FileHandler('vocabvoyage.log')
        file_handler.setLevel(logging.INFO)
        
        # æ§åˆ¶å°è™•ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.DEBUG)
        
        # æ ¼å¼åŒ–å™¨
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        logger.addHandler(file_handler)
        logger.addHandler(console_handler)
        
        return logger
    
    def log_user_action(self, user_id: str, action: str, details: dict = None):
        """è¨˜éŒ„ç”¨æˆ¶æ“ä½œ"""
        log_data = {
            'user_id': user_id,
            'action': action,
            'timestamp': datetime.now().isoformat(),
            'details': details or {}
        }
        self.logger.info(f"User Action: {log_data}")
    
    def log_api_call(self, service: str, endpoint: str, response_time: float):
        """è¨˜éŒ„ API å‘¼å«"""
        log_data = {
            'service': service,
            'endpoint': endpoint,
            'response_time': response_time,
            'timestamp': datetime.now().isoformat()
        }
        self.logger.info(f"API Call: {log_data}")
```

### 2. æ•ˆèƒ½ç›£æ§

```python
import time
from functools import wraps

def monitor_performance(func):
    """æ•ˆèƒ½ç›£æ§è£é£¾å™¨"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        
        try:
            result = func(*args, **kwargs)
            execution_time = time.time() - start_time
            
            # è¨˜éŒ„æˆåŠŸåŸ·è¡Œ
            logger.info(f"{func.__name__} executed in {execution_time:.2f}s")
            
            return result
            
        except Exception as e:
            execution_time = time.time() - start_time
            
            # è¨˜éŒ„åŸ·è¡ŒéŒ¯èª¤
            logger.error(f"{func.__name__} failed after {execution_time:.2f}s: {str(e)}")
            
            raise
    
    return wrapper

# ä½¿ç”¨ç¯„ä¾‹
@monitor_performance
def search_vocabulary(query: str) -> str:
    # è©å½™æŸ¥è©¢é‚è¼¯
    pass
```

### 3. å¥åº·æª¢æŸ¥

```python
class HealthChecker:
    """ç³»çµ±å¥åº·æª¢æŸ¥"""
    
    def __init__(self):
        """åˆå§‹åŒ–å¥åº·æª¢æŸ¥å™¨"""
        self.checks = {
            'database': self._check_database,
            'openai_api': self._check_openai_api,
            'chroma_db': self._check_chroma_db
        }
    
    def _check_database(self) -> bool:
        """æª¢æŸ¥ Firebase è³‡æ–™åº«é€£æ¥"""
        try:
            # æ¸¬è©¦è³‡æ–™åº«é€£æ¥
            # åŸ·è¡Œç°¡å–®æŸ¥è©¢
            return True
        except Exception:
            return False
    
    def _check_openai_api(self) -> bool:
        """æª¢æŸ¥ OpenAI API å¯ç”¨æ€§"""
        try:
            # æ¸¬è©¦ API é€£æ¥
            # åŸ·è¡Œç°¡å–®è«‹æ±‚
            return True
        except Exception:
            return False
    
    def _check_chroma_db(self) -> bool:
        """æª¢æŸ¥ ChromaDB å¯ç”¨æ€§"""
        try:
            # æ¸¬è©¦å‘é‡è³‡æ–™åº«é€£æ¥
            # åŸ·è¡Œç°¡å–®æŸ¥è©¢
            return True
        except Exception:
            return False
    
    def run_health_check(self) -> dict:
        """åŸ·è¡Œå®Œæ•´å¥åº·æª¢æŸ¥"""
        results = {}
        
        for service, check_func in self.checks.items():
            try:
                results[service] = {
                    'status': 'healthy' if check_func() else 'unhealthy',
                    'timestamp': datetime.now().isoformat()
                }
            except Exception as e:
                results[service] = {
                    'status': 'error',
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                }
        
        return results
```

## éƒ¨ç½²æ¶æ§‹

### 1. Docker å®¹å™¨åŒ–

```dockerfile
# å¤šéšæ®µå»ºç½® Dockerfile
FROM python:3.11-slim as builder

# å®‰è£ Poetry
RUN pip install poetry==1.7.1

# è¨­å®šå·¥ä½œç›®éŒ„
WORKDIR /app

# è¤‡è£½ä¾è³´æª”æ¡ˆ
COPY pyproject.toml poetry.lock* ./

# å®‰è£ä¾è³´
RUN poetry config virtualenvs.create false \
    && poetry install --no-dev --no-interaction --no-ansi

# ç”Ÿç”¢éšæ®µ
FROM python:3.11-slim as production

# è¤‡è£½å·²å®‰è£çš„å¥—ä»¶
COPY --from=builder /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages
COPY --from=builder /usr/local/bin /usr/local/bin

# è¨­å®šå·¥ä½œç›®éŒ„
WORKDIR /app

# è¤‡è£½æ‡‰ç”¨ç¨‹å¼æª”æ¡ˆ
COPY . .

# å»ºç«‹é root ç”¨æˆ¶
RUN useradd --create-home --shell /bin/bash app \
    && chown -R app:app /app
USER app

# è¨­å®šç’°å¢ƒè®Šæ•¸
ENV PYTHONPATH=/app
ENV PORT=8501

# å¥åº·æª¢æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:$PORT/_stcore/health || exit 1

# å•Ÿå‹•å‘½ä»¤
CMD streamlit run src/app.py --server.port $PORT --server.address 0.0.0.0
```

### 2. Docker Compose é…ç½®

```yaml
version: '3.8'

services:
  vocabvoyage:
    build: .
    ports:
      - "8501:8501"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - FIREBASE_DATABASE_URL=${FIREBASE_DATABASE_URL}
    volumes:
      - ./FirebaseKey.json:/app/FirebaseKey.json:ro
      - ./data:/app/data
      - ./logs:/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    
  # å¯é¸ï¼šRedis å¿«å–æœå‹™
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    
  # å¯é¸ï¼šç›£æ§æœå‹™
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
    restart: unless-stopped

volumes:
  redis_data:
```

### 3. Kubernetes éƒ¨ç½²

```yaml
# deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vocabvoyage
  labels:
    app: vocabvoyage
spec:
  replicas: 3
  selector:
    matchLabels:
      app: vocabvoyage
  template:
    metadata:
      labels:
        app: vocabvoyage
    spec:
      containers:
      - name: vocabvoyage
        image: vocabvoyage:latest
        ports:
        - containerPort: 8501
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: api-keys
              key: openai-api-key
        - name: FIREBASE_DATABASE_URL
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: firebase-url
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /_stcore/health
            port: 8501
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /_stcore/health
            port: 8501
          initialDelaySeconds: 5
          periodSeconds: 5

---
# service.yaml
apiVersion: v1
kind: Service
metadata:
  name: vocabvoyage-service
spec:
  selector:
    app: vocabvoyage
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8501
  type: LoadBalancer
```

## æ“´å±•æ€§æ¶æ§‹

### 1. æ°´å¹³æ“´å±•ç­–ç•¥

```python
class LoadBalancer:
    """è² è¼‰å‡è¡¡å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–è² è¼‰å‡è¡¡å™¨"""
        self.instances = []
        self.current_index = 0
    
    def add_instance(self, instance_url: str):
        """æ·»åŠ æœå‹™å¯¦ä¾‹"""
        self.instances.append(instance_url)
    
    def get_next_instance(self) -> str:
        """ç²å–ä¸‹ä¸€å€‹å¯ç”¨å¯¦ä¾‹ï¼ˆè¼ªè©¢ç­–ç•¥ï¼‰"""
        if not self.instances:
            raise Exception("æ²’æœ‰å¯ç”¨çš„æœå‹™å¯¦ä¾‹")
        
        instance = self.instances[self.current_index]
        self.current_index = (self.current_index + 1) % len(self.instances)
        
        return instance
```

### 2. å¾®æœå‹™æ¶æ§‹

```python
# è©å½™æœå‹™
class VocabularyService:
    """è©å½™ç®¡ç†å¾®æœå‹™"""
    
    def __init__(self):
        self.database = VocabDatabase()
    
    def search_word(self, word: str) -> dict:
        """è©å½™æŸ¥è©¢æœå‹™"""
        pass
    
    def add_word(self, user_id: str, word_data: dict) -> bool:
        """æ·»åŠ è©å½™æœå‹™"""
        pass

# AI æœå‹™
class AIService:
    """AI è™•ç†å¾®æœå‹™"""
    
    def __init__(self):
        self.llm_client = OpenAI()
    
    def generate_response(self, prompt: str) -> str:
        """ç”Ÿæˆ AI å›æ‡‰"""
        pass
    
    def generate_quiz(self, topic: str) -> dict:
        """ç”Ÿæˆæ¸¬é©—"""
        pass

# ç”¨æˆ¶æœå‹™
class UserService:
    """ç”¨æˆ¶ç®¡ç†å¾®æœå‹™"""
    
    def __init__(self):
        self.database = UserDatabase()
    
    def authenticate_user(self, credentials: dict) -> bool:
        """ç”¨æˆ¶èªè­‰"""
        pass
    
    def get_user_profile(self, user_id: str) -> dict:
        """ç²å–ç”¨æˆ¶è³‡æ–™"""
        pass
```

### 3. API Gateway

```python
from flask import Flask, request, jsonify
import requests

class APIGateway:
    """API é–˜é“å™¨"""
    
    def __init__(self):
        self.app = Flask(__name__)
        self.services = {
            'vocabulary': 'http://vocabulary-service:8001',
            'ai': 'http://ai-service:8002',
            'user': 'http://user-service:8003'
        }
        self._setup_routes()
    
    def _setup_routes(self):
        """è¨­å®šè·¯ç”±"""
        
        @self.app.route('/api/vocabulary/<path:path>', methods=['GET', 'POST'])
        def vocabulary_proxy(path):
            return self._proxy_request('vocabulary', path)
        
        @self.app.route('/api/ai/<path:path>', methods=['GET', 'POST'])
        def ai_proxy(path):
            return self._proxy_request('ai', path)
        
        @self.app.route('/api/user/<path:path>', methods=['GET', 'POST'])
        def user_proxy(path):
            return self._proxy_request('user', path)
    
    def _proxy_request(self, service: str, path: str):
        """ä»£ç†è«‹æ±‚åˆ°å°æ‡‰çš„å¾®æœå‹™"""
        service_url = self.services.get(service)
        if not service_url:
            return jsonify({'error': 'Service not found'}), 404
        
        # è½‰ç™¼è«‹æ±‚
        response = requests.request(
            method=request.method,
            url=f"{service_url}/{path}",
            headers=dict(request.headers),
            data=request.get_data(),
            params=request.args
        )
        
        return response.content, response.status_code, response.headers.items()
```

## ç¸½çµ

VocabVoyage çš„æ¶æ§‹è¨­è¨ˆé«”ç¾äº†ç¾ä»£ AI æ‡‰ç”¨çš„æœ€ä½³å¯¦è¸ï¼š

### æ ¸å¿ƒå„ªå‹¢

1. **æ¨¡çµ„åŒ–è¨­è¨ˆ**ï¼šå„çµ„ä»¶è·è²¬æ¸…æ™°ï¼Œä¾¿æ–¼ç¶­è­·å’Œæ“´å±•
2. **AI é©…å‹•**ï¼šå……åˆ†åˆ©ç”¨ LangGraph å’Œ RAG æŠ€è¡“æä¾›æ™ºèƒ½é«”é©—
3. **é›²ç«¯åŸç”Ÿ**ï¼šæ”¯æ´å®¹å™¨åŒ–éƒ¨ç½²å’Œæ°´å¹³æ“´å±•
4. **å®‰å…¨å¯é **ï¼šå®Œæ•´çš„å®‰å…¨æ©Ÿåˆ¶å’Œç›£æ§ç³»çµ±
5. **ç”¨æˆ¶å‹å–„**ï¼šç›´è§€çš„ä»‹é¢å’Œæµæš¢çš„äº’å‹•é«”é©—

### æŠ€è¡“å‰µæ–°

- **LangGraph å·¥ä½œæµç¨‹**ï¼šå¯¦ç¾è¤‡é›œçš„ AI æ±ºç­–é‚è¼¯
- **RAG æª¢ç´¢ç³»çµ±**ï¼šçµåˆå‘é‡æœå°‹å’Œç”Ÿæˆå¼ AI
- **å¤šæ¨¡å‹æ•´åˆ**ï¼šéˆæ´»é‹ç”¨ä¸åŒçš„ AI æ¨¡å‹
- **å³æ™‚è³‡æ–™åŒæ­¥**ï¼šFirebase æä¾›çš„é›²ç«¯åŒæ­¥èƒ½åŠ›

### æœªä¾†ç™¼å±•

é€™å€‹æ¶æ§‹ç‚ºæœªä¾†çš„åŠŸèƒ½æ“´å±•å¥ å®šäº†å …å¯¦åŸºç¤ï¼Œæ”¯æ´ï¼š
- å¤šèªè¨€å­¸ç¿’æ“´å±•
- èªéŸ³äº’å‹•åŠŸèƒ½
- ç¤¾äº¤å­¸ç¿’ç‰¹æ€§
- å€‹äººåŒ–æ¨è–¦ç³»çµ±
- å¤§è¦æ¨¡ç”¨æˆ¶æ”¯æ´

é€šéé€™å€‹å…¨é¢çš„æ¶æ§‹è¨­è¨ˆï¼ŒVocabVoyage ä¸åƒ…èƒ½å¤ æä¾›å„ªç§€çš„è‹±èªå­¸ç¿’é«”é©—ï¼Œä¹Ÿç‚º AI æ•™è‚²æ‡‰ç”¨çš„ç™¼å±•æä¾›äº†æœ‰åƒ¹å€¼çš„åƒè€ƒã€‚