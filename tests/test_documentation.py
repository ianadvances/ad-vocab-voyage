#!/usr/bin/env python3
"""
VocabVoyage æ–‡ä»¶å®Œæ•´æ€§é©—è­‰è…³æœ¬

æ­¤è…³æœ¬ç”¨æ–¼é©—è­‰å°ˆæ¡ˆæ–‡ä»¶çš„å®Œæ•´æ€§ï¼ŒåŒ…æ‹¬ï¼š
1. æª¢æŸ¥æ‰€æœ‰æ–‡ä»¶é€£çµæ­£ç¢ºæ€§
2. é©—è­‰å®‰è£æŒ‡å—å¯ä»¥æ­£å¸¸åŸ·è¡Œ
3. ç¢ºèªç¯„ä¾‹ç¨‹å¼å¯ä»¥é‹è¡Œ
4. æª¢æŸ¥æ‰€æœ‰ä¸­æ–‡è¨»è§£å’Œèªªæ˜å®Œæ•´

åŸ·è¡Œæ–¹å¼ï¼špython test_documentation.py
"""

import os
import sys
import re
import ast
import subprocess
from pathlib import Path
from typing import List, Dict, Tuple


class DocumentationTester:
    """æ–‡ä»¶å®Œæ•´æ€§æ¸¬è©¦é¡åˆ¥"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ¸¬è©¦ç’°å¢ƒ"""
        self.test_results = []
        self.project_root = Path(__file__).parent
    
    def test_markdown_links(self):
        """æ¸¬è©¦ Markdown æ–‡ä»¶ä¸­çš„é€£çµæ­£ç¢ºæ€§"""
        print("ğŸ”— æ¸¬è©¦æ–‡ä»¶é€£çµæ­£ç¢ºæ€§...")
        
        markdown_files = [
            "README.md",
            "docs/installation.md",
            "docs/usage.md",
            "docs/architecture.md"
        ]
        
        total_links = 0
        broken_links = []
        
        for md_file in markdown_files:
            file_path = self.project_root / md_file
            if not file_path.exists():
                print(f"   âŒ æ–‡ä»¶ä¸å­˜åœ¨: {md_file}")
                self.test_results.append(f"{md_file} å­˜åœ¨æ€§: å¤±æ•—")
                continue
            
            print(f"   ğŸ” æª¢æŸ¥ {md_file}...")
            
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æŸ¥æ‰¾ Markdown é€£çµ [text](url) å’Œåœ–ç‰‡ ![alt](url)
            link_pattern = r'!?\[([^\]]*)\]\(([^)]+)\)'
            links = re.findall(link_pattern, content)
            
            for link_text, link_url in links:
                total_links += 1
                
                # è·³éå¤–éƒ¨é€£çµï¼ˆhttp/httpsï¼‰
                if link_url.startswith(('http://', 'https://')):
                    continue
                
                # æª¢æŸ¥ç›¸å°è·¯å¾‘é€£çµ
                if link_url.startswith('#'):
                    # éŒ¨é»é€£çµï¼Œæš«æ™‚è·³é
                    continue
                
                # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
                if link_url.startswith('/'):
                    # çµ•å°è·¯å¾‘ï¼ˆç›¸å°æ–¼å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼‰
                    target_path = self.project_root / link_url.lstrip('/')
                else:
                    # ç›¸å°è·¯å¾‘
                    target_path = file_path.parent / link_url
                
                if not target_path.exists():
                    broken_links.append(f"{md_file}: {link_url}")
        
        if not broken_links:
            print(f"   âœ… æ‰€æœ‰ {total_links} å€‹å…§éƒ¨é€£çµéƒ½æœ‰æ•ˆ")
            self.test_results.append("æ–‡ä»¶é€£çµå®Œæ•´æ€§: é€šé")
        else:
            print(f"   âŒ ç™¼ç¾ {len(broken_links)} å€‹ç„¡æ•ˆé€£çµ:")
            for broken_link in broken_links:
                print(f"      - {broken_link}")
            self.test_results.append(f"æ–‡ä»¶é€£çµå®Œæ•´æ€§: å¤±æ•— - {len(broken_links)} å€‹ç„¡æ•ˆé€£çµ")
    
    def test_installation_guide(self):
        """æ¸¬è©¦å®‰è£æŒ‡å—çš„å¯åŸ·è¡Œæ€§"""
        print("\nğŸ“¦ æ¸¬è©¦å®‰è£æŒ‡å—å¯åŸ·è¡Œæ€§...")
        
        installation_file = self.project_root / "docs/installation.md"
        if not installation_file.exists():
            print("   âŒ å®‰è£æŒ‡å—ä¸å­˜åœ¨")
            self.test_results.append("å®‰è£æŒ‡å—å­˜åœ¨æ€§: å¤±æ•—")
            return
        
        with open(installation_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«é‡è¦çš„å®‰è£æ­¥é©Ÿ
        required_sections = [
            "poetry install",
            "docker",
            "ç’°å¢ƒè®Šæ•¸",
            "Firebase",
            "OpenAI"
        ]
        
        missing_sections = []
        for section in required_sections:
            if section.lower() not in content.lower():
                missing_sections.append(section)
        
        if not missing_sections:
            print("   âœ… å®‰è£æŒ‡å—åŒ…å«æ‰€æœ‰å¿…è¦æ­¥é©Ÿ")
            self.test_results.append("å®‰è£æŒ‡å—å®Œæ•´æ€§: é€šé")
        else:
            print(f"   âš ï¸  å®‰è£æŒ‡å—ç¼ºå°‘éƒ¨åˆ†å…§å®¹: {missing_sections}")
            self.test_results.append(f"å®‰è£æŒ‡å—å®Œæ•´æ€§: éƒ¨åˆ†é€šé - ç¼ºå°‘ {missing_sections}")
        
        # æª¢æŸ¥ä»£ç¢¼å¡Šæ ¼å¼
        code_blocks = re.findall(r'```[\s\S]*?```', content)
        if code_blocks:
            print(f"   âœ… æ‰¾åˆ° {len(code_blocks)} å€‹ä»£ç¢¼ç¯„ä¾‹")
            self.test_results.append("å®‰è£æŒ‡å—ä»£ç¢¼ç¯„ä¾‹: é€šé")
        else:
            print("   âš ï¸  å®‰è£æŒ‡å—ç¼ºå°‘ä»£ç¢¼ç¯„ä¾‹")
            self.test_results.append("å®‰è£æŒ‡å—ä»£ç¢¼ç¯„ä¾‹: éƒ¨åˆ†é€šé")
    
    def test_usage_guide(self):
        """æ¸¬è©¦ä½¿ç”¨æŒ‡å—çš„å®Œæ•´æ€§"""
        print("\nğŸ“– æ¸¬è©¦ä½¿ç”¨æŒ‡å—å®Œæ•´æ€§...")
        
        usage_file = self.project_root / "docs/usage.md"
        if not usage_file.exists():
            print("   âŒ ä½¿ç”¨æŒ‡å—ä¸å­˜åœ¨")
            self.test_results.append("ä½¿ç”¨æŒ‡å—å­˜åœ¨æ€§: å¤±æ•—")
            return
        
        with open(usage_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«é‡è¦çš„ä½¿ç”¨èªªæ˜
        required_features = [
            "è©å½™æŸ¥è©¢",
            "ä¸»é¡Œå­¸ç¿’",
            "æ¸¬é©—",
            "èŠå¤©",
            "å€‹äººè©å½™æœ¬"
        ]
        
        missing_features = []
        for feature in required_features:
            if feature not in content:
                missing_features.append(feature)
        
        if not missing_features:
            print("   âœ… ä½¿ç”¨æŒ‡å—æ¶µè“‹æ‰€æœ‰ä¸»è¦åŠŸèƒ½")
            self.test_results.append("ä½¿ç”¨æŒ‡å—åŠŸèƒ½è¦†è“‹: é€šé")
        else:
            print(f"   âš ï¸  ä½¿ç”¨æŒ‡å—ç¼ºå°‘åŠŸèƒ½èªªæ˜: {missing_features}")
            self.test_results.append(f"ä½¿ç”¨æŒ‡å—åŠŸèƒ½è¦†è“‹: éƒ¨åˆ†é€šé - ç¼ºå°‘ {missing_features}")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰ä½¿ç”¨ç¯„ä¾‹
        if "ç¯„ä¾‹" in content or "ä¾‹å­" in content or "ç¤ºä¾‹" in content:
            print("   âœ… ä½¿ç”¨æŒ‡å—åŒ…å«ä½¿ç”¨ç¯„ä¾‹")
            self.test_results.append("ä½¿ç”¨æŒ‡å—ç¯„ä¾‹: é€šé")
        else:
            print("   âš ï¸  ä½¿ç”¨æŒ‡å—ç¼ºå°‘ä½¿ç”¨ç¯„ä¾‹")
            self.test_results.append("ä½¿ç”¨æŒ‡å—ç¯„ä¾‹: éƒ¨åˆ†é€šé")
    
    def test_architecture_documentation(self):
        """æ¸¬è©¦æ¶æ§‹èªªæ˜æ–‡ä»¶"""
        print("\nğŸ—ï¸ æ¸¬è©¦æ¶æ§‹èªªæ˜æ–‡ä»¶...")
        
        arch_file = self.project_root / "docs/architecture.md"
        if not arch_file.exists():
            print("   âŒ æ¶æ§‹èªªæ˜æ–‡ä»¶ä¸å­˜åœ¨")
            self.test_results.append("æ¶æ§‹èªªæ˜æ–‡ä»¶å­˜åœ¨æ€§: å¤±æ•—")
            return
        
        with open(arch_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«é‡è¦çš„æ¶æ§‹èªªæ˜
        required_components = [
            "LangGraph",
            "RAG",
            "Firebase",
            "Streamlit",
            "OpenAI"
        ]
        
        missing_components = []
        for component in required_components:
            if component not in content:
                missing_components.append(component)
        
        if not missing_components:
            print("   âœ… æ¶æ§‹èªªæ˜æ¶µè“‹æ‰€æœ‰ä¸»è¦çµ„ä»¶")
            self.test_results.append("æ¶æ§‹èªªæ˜çµ„ä»¶è¦†è“‹: é€šé")
        else:
            print(f"   âš ï¸  æ¶æ§‹èªªæ˜ç¼ºå°‘çµ„ä»¶: {missing_components}")
            self.test_results.append(f"æ¶æ§‹èªªæ˜çµ„ä»¶è¦†è“‹: éƒ¨åˆ†é€šé - ç¼ºå°‘ {missing_components}")
    
    def test_example_files_syntax(self):
        """æ¸¬è©¦ç¯„ä¾‹æª”æ¡ˆèªæ³•æ­£ç¢ºæ€§"""
        print("\nğŸ’¡ æ¸¬è©¦ç¯„ä¾‹æª”æ¡ˆèªæ³•...")
        
        example_files = [
            "examples/langgraph_rag.py",
            "examples/langgraph_tools.py",
            "examples/notebooks/vocabulary_generator.py",
            "examples/notebooks/pdf_text_extraction.py",
            "examples/notebooks/vocabulary_write_to_chroma.py",
            "examples/notebooks/models_sqlite.py"
        ]
        
        syntax_errors = []
        
        for example_file in example_files:
            file_path = self.project_root / example_file
            if not file_path.exists():
                syntax_errors.append(f"{example_file}: æª”æ¡ˆä¸å­˜åœ¨")
                continue
            
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # æª¢æŸ¥ Python èªæ³•
                ast.parse(content)
                print(f"   âœ… {example_file} èªæ³•æ­£ç¢º")
                
            except SyntaxError as e:
                syntax_errors.append(f"{example_file}: èªæ³•éŒ¯èª¤ - {e}")
                print(f"   âŒ {example_file} èªæ³•éŒ¯èª¤: {e}")
            except Exception as e:
                syntax_errors.append(f"{example_file}: è®€å–éŒ¯èª¤ - {e}")
                print(f"   âŒ {example_file} è®€å–éŒ¯èª¤: {e}")
        
        if not syntax_errors:
            print("   âœ… æ‰€æœ‰ç¯„ä¾‹æª”æ¡ˆèªæ³•æ­£ç¢º")
            self.test_results.append("ç¯„ä¾‹æª”æ¡ˆèªæ³•: é€šé")
        else:
            print(f"   âŒ ç™¼ç¾ {len(syntax_errors)} å€‹èªæ³•å•é¡Œ")
            self.test_results.append(f"ç¯„ä¾‹æª”æ¡ˆèªæ³•: å¤±æ•— - {len(syntax_errors)} å€‹å•é¡Œ")
    
    def test_chinese_comments(self):
        """æ¸¬è©¦ä¸­æ–‡è¨»è§£å®Œæ•´æ€§"""
        print("\nğŸˆ³ æ¸¬è©¦ä¸­æ–‡è¨»è§£å®Œæ•´æ€§...")
        
        python_files = [
            "src/app.py",
            "src/agents.py",
            "src/database.py",
            "src/config.py"
        ]
        
        comment_stats = {}
        
        for py_file in python_files:
            file_path = self.project_root / py_file
            if not file_path.exists():
                comment_stats[py_file] = {"status": "æª”æ¡ˆä¸å­˜åœ¨"}
                continue
            
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # çµ±è¨ˆè¨»è§£
                total_functions = len(re.findall(r'def\s+\w+\s*\(', content))
                total_classes = len(re.findall(r'class\s+\w+', content))
                
                # æª¢æŸ¥ä¸­æ–‡ docstring
                chinese_docstrings = len(re.findall(r'"""[\s\S]*?[\u4e00-\u9fff][\s\S]*?"""', content))
                chinese_comments = len(re.findall(r'#.*[\u4e00-\u9fff]', content))
                
                comment_stats[py_file] = {
                    "functions": total_functions,
                    "classes": total_classes,
                    "chinese_docstrings": chinese_docstrings,
                    "chinese_comments": chinese_comments,
                    "status": "å·²åˆ†æ"
                }
                
                if chinese_docstrings > 0 or chinese_comments > 0:
                    print(f"   âœ… {py_file}: {chinese_docstrings} å€‹ä¸­æ–‡ docstring, {chinese_comments} å€‹ä¸­æ–‡è¨»è§£")
                else:
                    print(f"   âš ï¸  {py_file}: ç¼ºå°‘ä¸­æ–‡è¨»è§£")
                
            except Exception as e:
                comment_stats[py_file] = {"status": f"è®€å–éŒ¯èª¤: {e}"}
                print(f"   âŒ {py_file}: è®€å–éŒ¯èª¤ - {e}")
        
        # è©•ä¼°æ•´é«”ä¸­æ–‡è¨»è§£æƒ…æ³
        files_with_chinese = sum(1 for stats in comment_stats.values() 
                                if isinstance(stats, dict) and 
                                stats.get("chinese_docstrings", 0) > 0 or stats.get("chinese_comments", 0) > 0)
        
        total_analyzed = sum(1 for stats in comment_stats.values() 
                           if isinstance(stats, dict) and stats.get("status") == "å·²åˆ†æ")
        
        if files_with_chinese == total_analyzed and total_analyzed > 0:
            print("   âœ… æ‰€æœ‰æ ¸å¿ƒæª”æ¡ˆéƒ½åŒ…å«ä¸­æ–‡è¨»è§£")
            self.test_results.append("ä¸­æ–‡è¨»è§£å®Œæ•´æ€§: é€šé")
        elif files_with_chinese > 0:
            print(f"   âš ï¸  {files_with_chinese}/{total_analyzed} å€‹æª”æ¡ˆåŒ…å«ä¸­æ–‡è¨»è§£")
            self.test_results.append("ä¸­æ–‡è¨»è§£å®Œæ•´æ€§: éƒ¨åˆ†é€šé")
        else:
            print("   âŒ æ ¸å¿ƒæª”æ¡ˆç¼ºå°‘ä¸­æ–‡è¨»è§£")
            self.test_results.append("ä¸­æ–‡è¨»è§£å®Œæ•´æ€§: å¤±æ•—")
    
    def test_readme_completeness(self):
        """æ¸¬è©¦ README.md å®Œæ•´æ€§"""
        print("\nğŸ“„ æ¸¬è©¦ README.md å®Œæ•´æ€§...")
        
        readme_file = self.project_root / "README.md"
        if not readme_file.exists():
            print("   âŒ README.md ä¸å­˜åœ¨")
            self.test_results.append("README.md å­˜åœ¨æ€§: å¤±æ•—")
            return
        
        with open(readme_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æª¢æŸ¥å¿…è¦çš„ç« ç¯€
        required_sections = [
            "# VocabVoyage",  # æ¨™é¡Œ
            "## ä¸»è¦ç‰¹è‰²",     # åŠŸèƒ½èªªæ˜
            "## æŠ€è¡“æ¶æ§‹",     # æŠ€è¡“èªªæ˜
            "## å¿«é€Ÿé–‹å§‹",     # å®‰è£èªªæ˜
            "## æ ¸å¿ƒåŠŸèƒ½",     # ä½¿ç”¨èªªæ˜
        ]
        
        missing_sections = []
        for section in required_sections:
            if section not in content:
                missing_sections.append(section)
        
        if not missing_sections:
            print("   âœ… README.md åŒ…å«æ‰€æœ‰å¿…è¦ç« ç¯€")
            self.test_results.append("README.md ç« ç¯€å®Œæ•´æ€§: é€šé")
        else:
            print(f"   âš ï¸  README.md ç¼ºå°‘ç« ç¯€: {missing_sections}")
            self.test_results.append(f"README.md ç« ç¯€å®Œæ•´æ€§: éƒ¨åˆ†é€šé - ç¼ºå°‘ {missing_sections}")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰åœ–ç‰‡
        image_links = re.findall(r'!\[([^\]]*)\]\(([^)]+)\)', content)
        if image_links:
            print(f"   âœ… README.md åŒ…å« {len(image_links)} å€‹åœ–ç‰‡")
            self.test_results.append("README.md åœ–ç‰‡: é€šé")
        else:
            print("   âš ï¸  README.md ç¼ºå°‘åœ–ç‰‡")
            self.test_results.append("README.md åœ–ç‰‡: éƒ¨åˆ†é€šé")
    
    def print_test_summary(self):
        """æ‰“å°æ¸¬è©¦æ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ“Š æ–‡ä»¶å®Œæ•´æ€§æ¸¬è©¦çµæœæ‘˜è¦")
        print("="*60)
        
        passed = sum(1 for result in self.test_results if "é€šé" in result)
        partial = sum(1 for result in self.test_results if "éƒ¨åˆ†é€šé" in result)
        failed = sum(1 for result in self.test_results if "å¤±æ•—" in result)
        total = len(self.test_results)
        
        print(f"ç¸½æ¸¬è©¦æ•¸: {total}")
        print(f"é€šé: {passed}")
        print(f"éƒ¨åˆ†é€šé: {partial}")
        print(f"å¤±æ•—: {failed}")
        
        if total > 0:
            success_rate = (passed + partial) / total * 100
            print(f"æˆåŠŸç‡: {success_rate:.1f}%")
        
        print("\nè©³ç´°çµæœ:")
        for result in self.test_results:
            if "é€šé" in result:
                status = "âœ…"
            elif "éƒ¨åˆ†é€šé" in result:
                status = "âš ï¸"
            else:
                status = "âŒ"
            print(f"  {status} {result}")
        
        if failed == 0 and partial == 0:
            print("\nğŸ‰ æ‰€æœ‰æ–‡ä»¶å®Œæ•´æ€§æ¸¬è©¦é€šéï¼")
        elif failed == 0:
            print("\nâœ… æ–‡ä»¶åŸºæœ¬å®Œæ•´ï¼Œéƒ¨åˆ†é …ç›®å¯ä»¥é€²ä¸€æ­¥æ”¹å–„")
        else:
            print(f"\nâš ï¸  ç™¼ç¾ {failed} å€‹æ–‡ä»¶å•é¡Œï¼Œéœ€è¦ä¿®å¾©")
    
    def run_all_tests(self):
        """åŸ·è¡Œæ‰€æœ‰æ–‡ä»¶æ¸¬è©¦"""
        print("ğŸš€ é–‹å§‹ VocabVoyage æ–‡ä»¶å®Œæ•´æ€§é©—è­‰")
        print("="*60)
        
        # åŸ·è¡Œå„é …æ¸¬è©¦
        self.test_readme_completeness()
        self.test_markdown_links()
        self.test_installation_guide()
        self.test_usage_guide()
        self.test_architecture_documentation()
        self.test_example_files_syntax()
        self.test_chinese_comments()
        
        # æ‰“å°æ¸¬è©¦æ‘˜è¦
        self.print_test_summary()
        
        return True


def main():
    """ä¸»å‡½æ•¸"""
    tester = DocumentationTester()
    return tester.run_all_tests()


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)